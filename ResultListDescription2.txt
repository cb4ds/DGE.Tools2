Synopsis

	DGEobj is inspired by RSE and SLOA data structures but is designed to be a more flexible and extensible container of results from a DGE analysis.  Data items can be added as needed.  Several attributes are created to describe each data item.  Specifically, each item is categorized by both a "type" and a "basetype".  Moreover, the creation date is automatically captured in "dateCreated" and funArgs is a text field that provides a text copy of the function arguments used to create the data item (or an informative short note from the analyst).  New types can be defined and added to the dgeObj$objDef element which holds the object definition.  

	Each data item is "named" and the name connects the data item to its other attributes.  

	A basic design principal of the DGEobj is to keep it simple and flexible.  However, we've imposed one restriction that to create a DGEobj, you have to provide 3 items: a counts matrix, sample annotation (cols) and gene/transcript/exon annotation (rows).  We refer to the sample annotation as "design" info and the design table should have sufficient factor columns to describe the experiment completely.  

	The three essential items to initialize a DGEobj are: counts, gene/transcript/exon annotation and sample annotation.  These go in as; (itemName/itemType/temBasetype): counts/counts/assay, design/design/col and geneDat/geneDat/row (or isoformDat or exonDat depending which level you're working on).  These three items are also defined as unique which means that "type" can only appear once in a DGEobj.  Since these items are essentially the raw data collected to start an analysis, it makes sense to make them both required and unique.  The counts are the starting point, the raw data from the perspective of the data analyst.  So allowing only one set of counts makes it clear all other data in the DGEobj is derived from the counts entry.  This also has the pleasant side effect of making it easy to programmatically extract these basic data types in some downstream integrative analysis.  
 
Here is the list of list structure of the DGEobj:  
 
	dgeObj$data[[dataName]] = a named data item (usually a matrix or DF but could be any R object)
	dgeObj$type[[dataName]]  = a datatype for the data object (see type explanation below)
	dgeObj$basetype[[dataname]] = one of row, col, assay, meta
	dgeObj$dateCreated[[dataname]] = automatically captured date the item was added.
	dgeObj$funArgs[[dataname]] = documentation on how the data item was created (usually you'll use funArgs=match.call() to capture the function arguments that created the object).
	dgeObj$objDef = This is the extensible structure definition of the object
	
	The DGEobj is a list with 6 sublists.  
	
	The $data list holds all the data items depositied in this DGEobj.  Each data item is named and the names are used to index the other attrribute lists: $type, $basetype, $dateCreated and $funArgs.  

Default Type Definitions:
> names(d$objDef$type)
 [1] "row"          "col"          "assay"        "meta"         "counts"       "design"      
 [7] "geneDat"      "isoformDat"   "exonDat"      "topTable"     "topTreat"     "fit"         
[13] "designMatrix" "geneList"     "pathway"     

Basetype Definitions: 
> unlist(d$objDef$basetype)
    row     col   assay    meta 
  "row"   "col" "assay"  "meta" 

Extensible Type Features

	The basetypes can be used as a "type" tag for any data items that don't fit in one of the other predefined "type" buckets.  This allows people to add novel datatypes without any additional effort.  However,  if you'll be using alot of this type of data, you can use the newType function to create a new type definition.  The updated type definition is stored in the DGEobj as $objDef and the analyst can query the available data types with a showTypes function.  

 
Data annotation 

	If I give you a spreadsheet to work on with no data dictionary, we've got a problem.  So there's a real need to capture metadata describing the data items being stored.  The goal here is to impose just enough order in the caos so a downstream analyst knows what type of data s/he's dealing and the order in which they've bee created based solely on information contained in the object.  The opposing goal here is to not make documenting an object onerus.  We try to automate gathering the necessary information to make it painless.
	
	The type definition then, tells the downstream analyst what kind of object he's dealing with and provides means for the analyst to extract certain datatypes programmatically. Each "type" is associated with a "basetype".  There are 4 basetypes: row, col, assay, meta.  The basetypes are used to determine how to subset a given data item. And the types allow for a more granular definition of standard data types. 
	
	Operationally here's how it works...
	The dimensions of the DGEobj are the "assay" row and column dimensions where row = genes and col = samples.  All row objects (gene-oriented annotations) must have the same nrow as an "assay".  All "col" basetype must have number of rows the same as ncol(assay).  That's one row of column annotation for each sample in the dataset.  This is refered to as the "design" info because it typically include data columns describing the experimental factors in the dataset and, ideally, any addition biodata associated with the samples. The forth basetype, "meta", is used to store additional information about the experiment that is not keyed on the row or col dimension.
	
	So that's the technical description of how types and basetypes and dimensions work.  Here's the practical definition of row, col, assay and meta.  If you run dim on your data item and it matches on both row and col with dim on your DGEobj, it's an assay object.  If the rowcount matches the DGEobj rowcount only, It's a row basetype.  If the rowcount matches the colcount on the DGEobj, it's a col object.  If the item dimension don't match either DGEobj dimension,  it's a meta object.  For example a dim returned from a fit object or a DGEList object matches the row (gene) count but not the col count,  so these are basetype row.  The alignment stats on each sample (row=sample, col=alignment metric) would be a col basetype.  And other normalizations and transformations of assay data usually produce an assay basetype (e.g., TPM, FPKM, zFPKM, FPK).  A few examples of items you could assign to the meta basetype:  A URL to the Github for this project.  A URL to a markdown or report file, a URL to the experiment design doc in confluence. 

Use attributes to further annotate objects.

	The DGEobj has three predefined attributes:
		Dim: holds the dimension of the DGEobject
		level: one of "gene", "isoform" or "exon"
		PID: The PID or comma separated list of PIDs (input as a text string)

	Attributes on the data items themselves can be used to further document a data item.  For example, adding attributes of FC and Pval to a topTreat table provides documentation of the criteria used to filter that data frame.  


Accessor Functions

initDGEobj	Initialize a new DGEobj
addItem		Add a new data item to a DGEobj
rmItem		Remove a data item from a DGEobj
getItem		Return a specific named data item (or list of items)
getType		Return all data items of a specific type 
getBaseType	Return all data items of a specific basetype 
itemNames	Return the names of all data items
newType		Define a new data type
showTypes	Show the Type definition of a DGEobj

Coersion Functions
as.list		unclasses the DGEobj to a regular list
as.RSE		Convert to RangedSummarizedExperiment (not implemented yet)
as.ES		Convert to ExpressionSet (not implemented yet)

Overridden base functions
dim		Dim of a DGEobj is the dimension of it's assay components.
dimnames	Return the col (sample) and row (gene) names from the assay components.
print		Print a summary of the contents of a DGEobj.
'[' and '[['	Subsetting functions (not implemented yet)

 
JRT:  DGEtools integration Start using attributes to store details about each data:  e.g. Log2CPM should have a Normalization attribute with values of none, TMM, RLE, or whatever othe normalization may be used;  A topTreat table should have the FoldChang attribute set;  A Genelist could have a Foldchange and Pvalue attribute to define how it was selected.  A DGEList should have a Normalization attribute also.

modify print to include attributes

Ryan's feedback
So, this looks like a variation on the SLOA concept. You'll want to look at my code to see which methods you need to implement. Off the top of my head, you still need nrow, ncol, "[", "[[" and "$". Also, you might want a print method. The "[" method is tricky, because it needs to implement both matrix and list-style indexing. I forget exactly how to do this, but you can refer to my SLOA code.

For the implementation, I see you're using a list of item-type pairs. I would lean toward using two lists instead, or rather a list and a vector. Make the object just a standard list of all the items, such that if you were to run "unclass" on it you would just get a regular list (speaking of which, add an "as.list" method that does exactly that). Then, add the vector of item types, which should probably be a factor with a defined set of levels, as an attribute (see ?attr). You can make this a named vector to avoid having to keep it in the same order as the item list. Another possible option is to use a separate list for each item type. This makes it easier to write the subsetting methods, but harder to preserve the insertion order, if you care about that.

For the dimension, I wouldn't use a hidden .dim element in the backing list. I would either use an attribute or just infer the dimension from the elements of the object. For nrow, search for the first element that implies a row count and return its size, and likewise for ncol. If the list is empty or contains no elements that allows you to infer a dimension, return 0 for that dimension. 

For addItem, you want to limit the item type to a set of known types. For this, you need match.arg. You might also consider writing an "addItems" method for adding multiple items, taking a named list and a vector of types, with the type vector recycled as necessary. Alternatively, you could just leave items with unknown types alone.


http://www.cyclismo.org/tutorial/R/s3Classes.html#creating-methods

https://abhishek-tiwari.com/hacking/class-and-objects-in-r-s3-style

https://www.r-bloggers.com/a-simple-guide-to-s3-methods/



